{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "55e5e7c4bf4f211321d25b5cc25f5f90",
     "grade": false,
     "grade_id": "cell-492a99b0a8559f43",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 7 - Artifical neural network (ANN)\n",
    "The deadline for this assginment is 18.03 (Fri) 20:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5536f13171613027fbce4b745160645",
     "grade": false,
     "grade_id": "cell-3e54a6992c224640",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Being a subset of machine learning (ML) methods, **deep learning** follows the basic ML principle: find a hypothesis map out of a hypothesis space (represented by neural networks) that minimizes a chosen loss on datapoints. \n",
    "\n",
    "Neural networks are called networks because they are typically represened by composing together many different functions, and the computed values create a network-like structure. For example, we might have three functions $f^{(1)},f^{(2)}$and $f^{(3)}$ connected in a chain, to form $f(x)=f^{(3)}(f^{(2)}(f^{(1)}))$. In this case, $f{(1)}$is called the first layer of the network, $f^{(2)}$ is called the second layer, and so on. The overall length of the chain gives the depth of the network. Networks with multiple layers are called deep networks, hence the name deep learning.\n",
    "\n",
    "Typically the final layer is called the **output layer**, and represents the label that we want to predict. The training datapoints \"tell\" what the output layer must do at each datapoint - it should produce a value that is close to the desired label. The behaviour of other layers however, is not directly specified by the training data. Instead the learning algorithm decides how to use these layers to find the best approximation of the ideal map by minimizing (locally) the loss on the training dataset. Thus, these layers are called **hidden layers**. \n",
    "<img src=\"neural_network.png\" alt=\"neural network\" style=\"width:600px;height:350px;\">\n",
    "\n",
    "In this assignment a fully connected multi-layer neural network, also called feed-forward neural network or **Multilayer Perceptron (MLP)**, is used to represent a hypothesis space that includes highly non-linear functions. MLP is the simplest type of a neural network, where each cell (neuron) is 'connected' to all the cells from the next layer, and only the next layer uses its value.\n",
    "\n",
    "If you wish to gain understanding of how a neural network actually works and learns, [this video series](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) by 3blue1brown provides a briliant visual explanation.\n",
    "\n",
    "## Learning goals\n",
    "After successfully completing this assignment, you should be able to:\n",
    "* understand the difference of hypothesis maps between MLP and linear models\n",
    "* understand that activation functions are a key part of neural network design\n",
    "* train MLPs to complete a regression task\n",
    "* train MLPs to complete a classification task\n",
    "* have some basic understanding of gradient based learning of ANN weights\n",
    "* use grid-search for adjusting multiple MLP hyper-parameters such as number of layers and learning rate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:22:17.053943Z",
     "start_time": "2022-03-03T07:22:16.978400Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f203e9abcbe57f1de28c2a98c21ef2d",
     "grade": false,
     "grade_id": "cell-b1646d6583a8c55a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False  # enable code auto-completion\n",
    "import numpy as np #import numpy to work with arrays\n",
    "import pandas as pd #import pandas to manipulate the dataset\n",
    "from matplotlib import pyplot as plt #import the module matplotlib.pyplot to do visulization\n",
    "from sklearn.preprocessing import PolynomialFeatures    # function to generate polynomial and interaction features\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score    # function to calculate mean squared error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b44f92fb8bd5705372902197fbeb33b5",
     "grade": false,
     "grade_id": "cell-210e5717beb441eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Basic neural network structure\n",
    "Take a look at the image below, showing a very basic neural network, with one-element input layer `x` and output layer `y`, and a single hidden layer with 3 hidden units:\n",
    "\n",
    "![A simple neural network schema](network-schema.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d83dbd941f401ae0dfd9c88575266f12",
     "grade": false,
     "grade_id": "cell-d79251e1d5456153",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The process of calculating the output of the network is as follows. We have the network defined as above, and a bias vector `[bias1, bias2, bias3]` corresponding to the `hidden1, hidden2, hidden3` hidden units. Then:\n",
    "1. We multiply x with the first layer's weights, and add a constant bias term. We have obtained initial values of the hidden 'neuron' activations. A single value is calculated as:\n",
    "$$\n",
    "hidden_i = x * weight_{1i} + bias_i\n",
    "$$\n",
    "1. Simply multiplying and adding to the initial value of x would not let us represent any complex non-linear functions, so we need to introduce a non-linearity to our network. It is done via activation functions in the hidden layer, and the most common one is the rectified linear unit (ReLU):\n",
    "$$\n",
    "ReLU(x) = max(x, 0)\n",
    "$$\n",
    "It could be thought of as a function replacing negative values with 0s. We apply it to our hidden layer activations:\n",
    "$$\n",
    "hidden_i = ReLU(hidden_i)\n",
    "$$\n",
    "1. Now that we have the activation values, we multiply them with the final weights and sum the result together to obtain the final output:\n",
    "$$\n",
    "y = hidden_1 * weight_{21} + hidden_2 * weight_{22} + hidden_3 * weight_{23}\n",
    "$$\n",
    "\n",
    "Note that there is no bias in the last step. We also do not use ReLU anymore, as it is a simple regression network. However, for classification, you would use a different activation function for your output to turn it into a probability distribution - see [sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) (binary) or [softmax](https://en.wikipedia.org/wiki/Softmax_function) (multiclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a10c5c910fa9eb40752330e292911732",
     "grade": false,
     "grade_id": "cell-280f7d9b6d99df2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    \n",
    "# Student Task A7.1\n",
    "    \n",
    "Use your understanding of how a neural network works, to set the correct weights and biases for our toy neural network example from above, so that the resulting function `f(x) = y` is a non-linear function looking like this:\n",
    "![Neural Network hypothesis plot](network-triangle.png)\n",
    "    \n",
    "Note that this would not be possible with linear models we studied previously, such as linear regression or SVMs.\n",
    "\n",
    "The vertices of the triangle must be the points `(0, 0), (1, 1), (2, 0)`. Fill in the missing (`None`) values in the `weights_1`, `weights_2`, and `bias` vectors. There is no need to change the values that have already been set!\n",
    "    \n",
    "Hint:  Try it out as a math problem with pen and paper if you have trouble! Try to think what are the already given functions $hidden_1(x)$ and $hidden_3(x)$, what unknowns there are in $hidden_2$, and what is the result of adding them together to obtain $y = f(x) = hidden_1(x) + hidden_2(x) + hidden_3(X)$ - e.g. with the given values:\n",
    "    \n",
    "$\n",
    "hidden_3(x) = 1 * x - 2 \n",
    "$; for `x > 2`(i.e.`(1*x-2) > 0`)\n",
    "    \n",
    "$\n",
    "hidden_3(x) = 0\n",
    "$; otherwise\n",
    "    \n",
    "There are also visualizations of the intermediate plots below.\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T07:28:38.406456Z",
     "start_time": "2022-03-02T07:28:38.383893Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab6318f8076f457a9631cfe642e8a4c1",
     "grade": false,
     "grade_id": "cell-dbf4dbecf5b02c26",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 1.]\n",
      "[ 0. -2. -2.]\n"
     ]
    }
   ],
   "source": [
    "## In the following two lines of code, please fill in the None values in a way allowing you to obtain \n",
    "## the given hyphothesis shape.  No need to change the given values in weights_1, bias.\n",
    "\n",
    "weights_1 = np.array([1., 2., 1.])     # a vector represents [w11, w12, w13]\n",
    "bias = np.array([0., -2, -2.])         # a vector represents [bias1, bias2, bias3]\n",
    "print(weights_1)\n",
    "print(bias)\n",
    "# YOUR CODE HERE\n",
    "weights_2 = np.array([1, -1, 1])         # a vector represents [w21, w22, w23]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:41:21.127165Z",
     "start_time": "2022-03-03T07:41:21.120027Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "921b74b452078df6e565240d68daef61",
     "grade": false,
     "grade_id": "cell-de33b87b47ab62a6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def hidden(x, weights_1, bias):\n",
    "    \"\"\"\n",
    "    Inputs: x,feature,scalar\n",
    "            weights_1, vector, [w11,w12,w13]\n",
    "            bias, vector, [bias1,bias2,bias3]\n",
    "    Output: activations, vector\n",
    "    \"\"\"\n",
    "    hidden_x = x * weights_1 + bias \n",
    "    return np.maximum(hidden_x, 0) # Apply the ReLU activation\n",
    "\n",
    "def network(x, weights_1, bias, weights_2):\n",
    "    \"\"\"\n",
    "    Inputs: x, feature,scalar\n",
    "            weights_1, vector, [w11,w12,w13]\n",
    "            bias, vector, [bias1,bias2,bias3]\n",
    "            weights_2, vector, [w21,w22,w23]\n",
    "    Output: predicted label, scalar\n",
    "    \"\"\"\n",
    "    hidden_x = hidden(x, weights_1, bias) # Calculate the hidden activations\n",
    "    final_x = hidden_x * weights_2 # Multiply them with the final weights [w21, w22, w23]\n",
    "    return sum(final_x) # Sum the result to obtain the final prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "659e786038af3d1e4fa1e58088eff679",
     "grade": false,
     "grade_id": "cell-87a928b374d7483c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's check how the results look visually, starting with the hidden layer activations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:41:22.511111Z",
     "start_time": "2022-03-03T07:41:22.506230Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd4e3faa1f332d64751940ac87b39231",
     "grade": false,
     "grade_id": "cell-b70d154dd62a78ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_to_plot = np.linspace(-0.5, 2.5, 99) # X values to serve as inputs for our network for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:41:23.836565Z",
     "start_time": "2022-03-03T07:41:23.425214Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9183e9336f88ccd2a1e8543f38f7ea39",
     "grade": false,
     "grade_id": "cell-45d54a00e4969cf8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x864 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 12))\n",
    "for i in range(3):\n",
    "    plt.tight_layout()\n",
    "    plt.subplot(3, 1, i + 1)\n",
    "    \n",
    "    # Compute the hidden layer activations\n",
    "    hidden_to_plot = [hidden(x, weights_1, bias)[i] for x in x_to_plot]\n",
    "    \n",
    "    # Make sure all plots use the same scale\n",
    "    plt.xlim(-0.5, 2.5) \n",
    "    plt.ylim(-0.5, 1.5)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    # Plot the hidden layer activations\n",
    "    plt.title(f'Hidden {i + 1} plot')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel(f'h{i + 1}')\n",
    "    plt.plot(x_to_plot, hidden_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e248ef65148663970bce3584692ea2f",
     "grade": false,
     "grade_id": "cell-6ec772ac29d74f37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's add the hidden activations multiplied by `weights_2` together, and plot the final hyphothesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:41:26.126625Z",
     "start_time": "2022-03-03T07:41:25.895692Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5f53f8ee4036086ca0cc8754810b6b2",
     "grade": false,
     "grade_id": "cell-39e8c42bf0426bf9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faa279efd00>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_to_plot = [network(x, weights_1, bias, weights_2) for x in x_to_plot] # Use our network to obtain y values\n",
    "plt.title('Neural Network toy example hyphothesis function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.plot(x_to_plot, y_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:41:28.438223Z",
     "start_time": "2022-03-03T07:41:28.431162Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "384338ae32bf46a5967d801d328bad1e",
     "grade": false,
     "grade_id": "cell-87790d570306eb38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check the resulting values:\n",
    "assert np.isclose(network(0, weights_1, bias, weights_2), 0.)\n",
    "assert np.isclose(network(1, weights_1, bias, weights_2), 1.)\n",
    "assert np.isclose(network(2, weights_1, bias, weights_2), 0.)\n",
    "assert np.isclose(y_to_plot[0], 0.)\n",
    "assert np.isclose(y_to_plot[-1], 0.)\n",
    "assert np.isclose(y_to_plot[len(y_to_plot) // 2], 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:41:29.468825Z",
     "start_time": "2022-03-03T07:41:29.462227Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55b3bcc5bd35a4b19a1ee51fda7d52fd",
     "grade": true,
     "grade_id": "cell-0fe9301658bb5487",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell for A7.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff4db8e81d8898fe6be154ed889803a7",
     "grade": false,
     "grade_id": "cell-23c466359525c199",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Dataset for this assignment\n",
    "We are going to reuse the dataset we have been working with in the previous assignments, but this time we will formulate a different ML problem: predicting air temperature by using history records, in particular, the label is air temperature at 00:00 of a given day, the features are air temperatures of previous 5 days at the same time, 00:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:44:30.029108Z",
     "start_time": "2022-03-03T07:44:29.994720Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b77b72b3ffcd9af37949255c4027016f",
     "grade": false,
     "grade_id": "cell-c690a103a271c67a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>m</th>\n",
       "      <th>d</th>\n",
       "      <th>time</th>\n",
       "      <th>air temperature</th>\n",
       "      <th>pre_1</th>\n",
       "      <th>pre_2</th>\n",
       "      <th>pre_3</th>\n",
       "      <th>pre_4</th>\n",
       "      <th>pre_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>00:00</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>00:00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>00:00</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>00:00</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  m   d   time  air temperature  pre_1  pre_2  pre_3  pre_4  pre_5\n",
       "10  2020  1   6  00:00              1.5   -1.6    1.7    4.6    3.6    1.5\n",
       "12  2020  1   7  00:00              4.5    1.5   -1.6    1.7    4.6    3.6\n",
       "14  2020  1   8  00:00              5.3    4.5    1.5   -1.6    1.7    4.6\n",
       "16  2020  1   9  00:00              2.1    5.3    4.5    1.5   -1.6    1.7\n",
       "18  2020  1  10  00:00             -2.0    2.1    5.3    4.5    1.5   -1.6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data stored in the file 'FMIData_Assignment7.csv' and clean the dataset\n",
    "data = pd.read_csv('FMIData_Assignment7.csv')\n",
    "# drop unrelevant columns\n",
    "data.drop(columns=['Time zone','Precipitation amount (mm)','Snow depth (cm)',\\\n",
    "                 'Ground minimum temperature (degC)','Maximum temperature (degC)', 'Minimum temperature (degC)'],inplace=True)  \n",
    "data.columns =['year','m','d','time','air temperature'] # rename columns \n",
    "\n",
    "# Select only weather recordings whose property 'time' is equal to `00:00`\n",
    "data = data[data['time'] == '00:00']\n",
    "\n",
    "# Shift the column 'air temperatrue' by different periods to obtain history records\n",
    "data['pre_1'] = data['air temperature'].shift(1)\n",
    "data['pre_2'] = data['air temperature'].shift(2)\n",
    "data['pre_3'] = data['air temperature'].shift(3)\n",
    "data['pre_4'] = data['air temperature'].shift(4)\n",
    "data['pre_5'] = data['air temperature'].shift(5)\n",
    "\n",
    "data = data.iloc[5:] # drop the first 5 rows which involves NAN\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7de41a6b4e8d06009c3125bd2a53787",
     "grade": false,
     "grade_id": "cell-09b4e74d2340fe62",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "    \n",
    "# Student Task A7.2\n",
    "\n",
    "In this problem formulation, a datapoint represents a day corresponding to a row in the dataframe. The column \"air temperature\" stores the labels and columns 'pre_1', 'pre_2', 'pre_3', 'pre_4', 'pre_5' are used as features.\n",
    "    \n",
    "Before training an MLP, let's firstly try out the old method we used before: PolynomialRegression. \n",
    "    \n",
    "As usual, we create the feature matrix and label vector and then train several models with different polynomial degrees to see which one is ideal.\n",
    "\n",
    "**Your task** is: create a feature matrix and a label vector\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:48:33.069186Z",
     "start_time": "2022-03-03T07:48:33.061851Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b17e46979aeb4a8259a9ac63c505f468",
     "grade": false,
     "grade_id": "cell-e71ea28f50254a6e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  m   d   time  air temperature  pre_1  pre_2  pre_3  pre_4  pre_5\n",
      "10  2020  1   6  00:00              1.5   -1.6    1.7    4.6    3.6    1.5\n",
      "12  2020  1   7  00:00              4.5    1.5   -1.6    1.7    4.6    3.6\n",
      "14  2020  1   8  00:00              5.3    4.5    1.5   -1.6    1.7    4.6\n",
      "16  2020  1   9  00:00              2.1    5.3    4.5    1.5   -1.6    1.7\n",
      "18  2020  1  10  00:00             -2.0    2.1    5.3    4.5    1.5   -1.6\n",
      "[[ -1.6   1.7   4.6   3.6   1.5]\n",
      " [  1.5  -1.6   1.7   4.6   3.6]\n",
      " [  4.5   1.5  -1.6   1.7   4.6]\n",
      " ...\n",
      " [ -2.2  -7.2 -15.4 -14.2 -13. ]\n",
      " [  0.1  -2.2  -7.2 -15.4 -14.2]\n",
      " [  1.2   0.1  -2.2  -7.2 -15.4]]\n",
      "[  1.5   4.5   5.3   2.1  -2.    0.    5.2   1.6   3.3   5.8   5.    4.\n",
      "   3.5   3.6   3.3   5.2   1.2   0.    1.7   0.3   2.9   0.6   3.    1.8\n",
      "   1.7   1.9   2.5   3.8  -0.5  -4.6  -1.3  -3.3  -3.5   0.9   3.3   3.8\n",
      "   3.1   2.6   1.8  -1.    1.9   3.7   5.1   5.1   3.8   1.2   3.    3.9\n",
      "   3.4   1.6  -1.7  -1.2  -3.4  -3.8  -2.8   1.6   3.3   2.4   2.    2.9\n",
      "   2.1   1.1   1.2   3.9   3.6   3.3   3.9   1.1  -2.4   1.1   3.2   1.7\n",
      "   4.6   4.2   0.6  -1.9  -1.1   1.6   3.6   5.1   4.9   3.9   5.6  -0.2\n",
      "  -1.2  -0.7   3.6   4.5   2.2   2.5   3.    6.    7.6   6.4   6.    3.2\n",
      "   3.7   4.2   4.2   2.    3.    2.7   4.2   5.9   6.4   9.3  10.6   8.\n",
      "   8.6   6.6   4.4   5.    4.9   4.4   2.4   3.4   6.2   8.5   8.7   6.4\n",
      "  10.1  11.2   8.8   8.2  10.   10.2   4.8   5.1   4.2   6.1   5.5   5.4\n",
      "   5.4   7.1   7.1   8.2  10.9  11.4  12.4  11.1  14.8  16.9  15.3  13.7\n",
      "  13.7  16.   15.5  12.7  12.7  13.7  14.2  13.5  13.7  14.6  15.4  15.2\n",
      "  18.5  17.4  18.4  17.9  18.4  19.6  21.3  21.1  20.2  21.8  19.3  17.4\n",
      "  17.5  20.1  22.5  24.   22.6  23.6  21.4  18.5  15.7  16.2  16.   16.9\n",
      "  15.2  15.5  16.1  14.5  14.5  14.1  15.8  13.9  15.6  14.8  15.   17.6\n",
      "  19.2  21.   20.6  20.6  20.9  19.3  15.3  14.2  14.4  15.3  17.7  19.3\n",
      "  17.5  16.9  15.9  17.8  16.7  16.6  16.5  16.1  16.9  17.2  19.   21.6\n",
      "  21.7  18.9  15.6  14.8  14.8  16.9  19.2  21.   17.2  17.5  19.   19.4\n",
      "  20.3  18.1  19.8  16.1  15.1  13.8  13.6  13.4  14.2  13.   13.3  13.4\n",
      "  14.1  16.4  16.1  15.3  14.5  13.6  12.2  13.   12.8  11.9  13.7  12.9\n",
      "  13.2  13.3  13.8   9.2  10.3  10.5  10.7  12.6  12.4  14.   16.2  15.5\n",
      "  15.3  15.7  14.1  13.2  13.1  11.7  12.7  12.9  12.9  14.5  14.2  12.9\n",
      "  12.9  11.7  11.5  10.6   9.6   8.4   6.6   5.2   3.4   6.1   4.5   2.\n",
      "   0.9   5.9   9.9   7.9   3.5   5.9  10.   10.9   9.7  10.    8.7   7.2\n",
      "   8.5   7.9  10.6   7.5   7.3   8.1   8.4   4.2   4.    1.    5.1   6.9\n",
      "   5.5   4.4   3.9   4.4   5.9   9.6   8.3   0.1   2.2   6.2   4.5   2.5\n",
      "   3.8   5.6   0.9   1.3   0.5   0.6   4.    2.7   0.    1.4   3.7   3.7\n",
      "   1.8  -0.5  -2.   -1.5  -1.    1.2  -1.3  -0.9   1.8   2.9   1.4   3.2\n",
      "   4.1   4.9   3.4   4.    2.2   2.1   0.4  -1.6   0.6   0.3   0.8   2.6\n",
      "   1.8   1.7  -0.4  -2.8  -1.5  -3.   -3.2  -1.4  -2.9  -7.2  -4.9  -0.3\n",
      "  -1.1  -4.8 -14.4 -18.8 -16.2 -12.3  -6.9  -0.4  -4.2  -4.4   1.5   2.7\n",
      "   1.7   0.8   0.8   0.3  -3.5  -3.8  -6.1  -6.9  -7.7  -4.4  -7.4 -13.3\n",
      " -14.9 -13.4  -8.5  -7.8 -11.6 -13.3 -16.  -13.5  -4.8  -6.1  -7.8  -5.7\n",
      " -14.7 -14.2  -6.   -3.   -0.3  -7.4  -4.9  -1.    2.8   3.2   2.1   4.3\n",
      "   3.3   3.4   2.   -1.7  -4.4  -1.6  -4.3  -6.1  -7.4 -10.8  -3.9  -1.6\n",
      "   1.3   0.5   0.9   0.2  -0.1  -2.8  -5.4  -1.9   1.4  -1.1   1.3   2.\n",
      "   3.3   2.6   4.5   4.3   3.2   4.7   5.6   4.6   3.1   3.7   4.    2.4\n",
      "   2.2   3.2   3.8   2.6   2.9   5.3   8.8   5.8   4.3   5.5   8.4  10.\n",
      "  10.2   8.8   7.4   7.1   6.6   2.9   2.1   3.4   3.3   3.8   3.3   4.\n",
      "   5.    5.5   4.8   6.5   6.9   3.8   5.7   4.5   5.9   6.9  11.3  17.1\n",
      "  16.9  17.3  13.7  14.5  13.3  12.8  12.3  12.1  12.3  10.5  10.8  11.3\n",
      "  12.   11.5   9.4  10.   11.5  11.1  11.6  11.8  13.7  16.9  17.5  17.8\n",
      "  19.5  18.6  19.6  18.4  18.5  19.2  19.9  18.2  15.6  15.9  16.2  16.8\n",
      "  16.9  20.8  22.6  24.4  26.5  25.7  22.4  20.6  20.8  21.4  21.3  21.6\n",
      "  22.7  20.7  22.1  20.6  22.1  22.7  23.6  23.8  24.   22.9  22.   25.8\n",
      "  23.4  22.9  24.8  26.3  26.7  25.1  21.8  22.   18.2  17.1  16.6  18.7\n",
      "  17.9  17.4  20.2  23.4  24.   20.1  20.6  16.5  17.6  18.   18.   15.\n",
      "  14.6  15.7  17.9  15.9  18.5  17.7  17.7  17.6  18.   18.8  18.   15.8\n",
      "  16.9  17.5  15.   14.6  15.6  14.4  14.2  12.4  11.9  12.1  13.5  13.2\n",
      "  16.6  16.3  15.6  14.8  12.1  11.   10.    8.9   9.2  12.6  11.7  14.4\n",
      "  15.   13.   14.3  14.2  12.9   9.6   7.7   8.    8.5   8.6   8.1   7.6\n",
      "   6.2   5.9   8.6   8.4   9.9  10.2   8.3   8.7   9.9   9.8   9.7  10.8\n",
      "  11.1  11.8  10.7  12.1  10.9  11.4  11.5  11.1  10.2   8.4   6.6   6.4\n",
      "   8.3   5.9   5.2   4.4   2.5   8.1  10.4   5.6   1.9   2.1   8.9   8.2\n",
      "   7.8   8.2   9.8   8.7   8.7   8.7   7.2   7.2   7.9   6.6   4.4   2.9\n",
      "   0.9   0.4   7.7   5.9   5.4   2.    0.5   0.9   5.7   5.5   4.1   2.5\n",
      "   3.3  -0.3  -2.2   0.4   2.7   4.4  -1.8  -7.1  -6.4  -5.3  -8.9  -7.2\n",
      "  -8.4  -9.6  -8.3 -15.  -13.  -14.2 -15.4  -7.2  -2.2   0.1   1.2   1.2]\n",
      "(708, 5)\n",
      "(708,)\n"
     ]
    }
   ],
   "source": [
    "## Create feature matrix and label vector:\n",
    "print(data.head())\n",
    "X = data[[\"pre_1\",\"pre_2\",\"pre_3\",\"pre_4\",\"pre_5\"]].values\n",
    "y = data['air temperature'].values\n",
    "#X = data.to_numpy()[:, 5: 10].astype(np.float)      # features are air temperatures of previous 5 days \n",
    "print(X)\n",
    "#y = data.to_numpy()[:, 4].astype(np.float)        # label is air temperature of the present day\n",
    "print(y)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "#print(X[1][1] + y[1])\n",
    "assert X.ndim == 2,  \"Wrong dimension of X\"  #sanity check the dimension of X\n",
    "assert X.shape[1] == 5, \"wrong shape of X\"  #sanity check the shape of X\n",
    "assert y.ndim == 1,  \"Wrong dimension of y\"  #sanity check the dimension of y\n",
    "assert y.shape[0] == 708, \"Wrong shape of y\" #sanity check the shape of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:50:25.179659Z",
     "start_time": "2022-03-03T07:50:25.169567Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b51e3f1abf250e54e42fa03fa85ce07f",
     "grade": true,
     "grade_id": "cell-9ea0a54f6e715495",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this is the test cell for A7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:50:25.714185Z",
     "start_time": "2022-03-03T07:50:25.700716Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "982308409d088d653296a4288a86aee5",
     "grade": false,
     "grade_id": "cell-8b28343eba12486a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "# Split the dataset into a training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:51:19.766242Z",
     "start_time": "2022-03-03T07:51:19.697244Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c70f847fe3e6b745f45b6497f94a0907",
     "grade": false,
     "grade_id": "cell-2e5f6017b78f30fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## define a list of values for the maximum polynomial degree \n",
    "degrees = [1,2,3,4]    \n",
    "\n",
    "# we will use this variables to store the resulting training and validation errors for each polynomial degree\n",
    "linear_tr_errors = []          \n",
    "linear_val_errors = []\n",
    "for degree in degrees:    # use for-loop to fit polynomial regression models with different degrees\n",
    "    lin_regr = LinearRegression(fit_intercept=False) # NOTE: \"fit_intercept=False\" as we already have a constant iterm in the new feature X_poly\n",
    "    poly = PolynomialFeatures(degree=degree)    # generate polynomial features\n",
    "    X_train_poly = poly.fit_transform(X_train)    # fit the raw features\n",
    "    lin_regr.fit(X_train_poly, y_train)    # apply linear regression to these new features and labels\n",
    "  \n",
    "    y_pred_train = lin_regr.predict(X_train_poly)    # predict using the linear model\n",
    "    tr_error = mean_squared_error(y_train, y_pred_train)    # calculate the training error\n",
    "    X_val_poly = poly.transform(X_val) # transform the raw features for the validation data \n",
    "    y_pred_val = lin_regr.predict(X_val_poly) # predict values for the validation data using the linear model \n",
    "    val_error = mean_squared_error(y_val, y_pred_val) # calculate the validation error\n",
    " \n",
    "    linear_tr_errors.append(tr_error)\n",
    "    linear_val_errors.append(val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:51:36.110771Z",
     "start_time": "2022-03-03T07:51:36.096809Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "861f84d2734da2ee7158c64dfe6db9bc",
     "grade": false,
     "grade_id": "cell-df9d6c102c8b28ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create a table to compare training and validation errors\n",
    "errors = {\"poly degree\":degrees,\n",
    "          \"linear_train_errors\":linear_tr_errors,\n",
    "          \"linear_val_errors\":linear_val_errors,\n",
    "         }\n",
    "pd.DataFrame({ key:pd.Series(value) for key, value in errors.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b50917d2afe5b6d2d1d8c6d7bd76cbc2",
     "grade": false,
     "grade_id": "cell-febf413f5a1ba202",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "# Student Task A7.3\n",
    "\n",
    "Answer the following quiz questions by setting the corresponding variable to the index of the answer that you consider correct. \n",
    "    \n",
    "Question 1: Which of the models from A7.2 would you recommend based on the above table?\n",
    "- Answer 1: Degree 1\n",
    "- Answer 2: Degree 2\n",
    "- Answer 3: Degree 3\n",
    "- Answer 4: Degree 4\n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:53:51.831106Z",
     "start_time": "2022-03-03T07:53:51.823644Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "838a0f5076dbf11d42ba991bb319b6bc",
     "grade": false,
     "grade_id": "cell-e19276eec668530b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## set Answer_Q1 to the index (starting from 1 !!!) of the correct answer (e.g., Answer_Q1=1 if you think Answer 1 is correct)\n",
    "Answer_Q1 = 2  \n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"my answer is: \", Answer_Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:53:54.596350Z",
     "start_time": "2022-03-03T07:53:54.591213Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "914c116bf5e85dced8b4e0db790ecff3",
     "grade": false,
     "grade_id": "cell-c8fa82c10c39dc67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check datatype of Answer_Q1\n",
    "assert Answer_Q1 in (1, 2, 3, 4), \"Please answer with a number from 1 to 4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T07:53:59.206805Z",
     "start_time": "2022-03-03T07:53:59.202384Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c16557f1e4b3ba1a2954268f55bbfeb",
     "grade": true,
     "grade_id": "cell-1df99e14ee864d56",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this is the test cell for A7.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ddb45f39eb6590d37d34d4b2da0d9d37",
     "grade": false,
     "grade_id": "cell-565f109e0c3ba1ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "# Student Task A7.4\n",
    "\n",
    "Now, we know the performance of polynomial regression on this prediction task. It is time to try out MLP and see whether MLP can defeat polynomial regression or not.\n",
    "\n",
    "We will still focus on Sklearn library and use Sklearn class [MLPRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html) to implement our model, but for complicated modern deep learning tasks, Python provides other easy-to-use libraries for the design and training of ANN, such as [Keras](https://keras.io/).\n",
    "\n",
    "\n",
    "**Hypothesis Space used in this task - MLP Structure:**\n",
    "- one input layer consists of the individual features (5 features) and is the entry point to the MLP.\n",
    "- several hidden layers with 15 neuron units in each layer and [ReLU activation function](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)), we will explore the number of hidden layers in this task, find out the ideal number of hidden layers for this given ML problem.\n",
    "\n",
    "- one final output layer with 1 neuron unit.\n",
    "\n",
    "For regularization strength and learning rate, default values are used.\n",
    "\n",
    "**Loss used in this task**: MSE\n",
    "\n",
    "In the following solution cell, you will:\n",
    "- Initialise an MLPRegressor, please use the `hidden_layer_sizes` defined for you and set `max_iter` to 1000, `random_state` to 42.\n",
    "- Train the regressor on the training set.\n",
    "- Evaluate the regressor on the training set and validation set.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:15:46.430389Z",
     "start_time": "2022-03-03T08:15:40.026597Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b004407f114a0b87cf44242d7989b80",
     "grade": false,
     "grade_id": "cell-deeeab95715eb643",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "## define a list of values for the number of hidden layers\n",
    "num_layers = [1,2,4,6,8,10]    # number of hidden layers\n",
    "num_neurons = 15  # number of neurons in each layer\n",
    "\n",
    "\n",
    "# we will use this variable to store the resulting training errors corresponding to different hidden-layer numbers\n",
    "mlp_tr_errors = []          \n",
    "mlp_val_errors = []\n",
    "\n",
    "for i, num in enumerate(num_layers):\n",
    "    hidden_layer_sizes = tuple([num_neurons]*num) # size (num of neurons) of each layer stacked in a tuple\n",
    "    \n",
    "    mlp_regr = MLPRegressor(hidden_layer_sizes = hidden_layer_sizes, max_iter = 1000, random_state = 42) # Initialise an MLPRegressor\n",
    " \n",
    "    mlp_regr.fit(X_train, y_train)    # Train MLP on the training set\n",
    "    \n",
    "    '''\n",
    ">>> X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "...                                                     random_state=1)\n",
    ">>> regr = MLPRegressor(hidden_layer_sizes = hidden_layer_sizes, max_iter = 1000, random_state=42).fit(X_train, y_train)\n",
    ">>> regr.predict(X_test[:2])\n",
    "array([-0.9..., -7.1...])\n",
    ">>> regr.score(X_test, y_test)\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    ## evaluate the trained MLP on both training set and validation set\n",
    "    y_pred_train = mlp_regr.predict(X_train)    # predict on the training set\n",
    "    tr_error = mean_squared_error(y_train, y_pred_train)    # calculate the training error\n",
    "    y_pred_val = mlp_regr.predict(X_val) # predict values for the validation data \n",
    "    val_error = mean_squared_error(y_val, y_pred_val) # calculate the validation error\n",
    "    \n",
    "    # sanity check num of layers\n",
    "    assert mlp_regr.n_layers_ == num_layers[i]+2 # total layers = num of hidden layers + input layer + output layer\n",
    "    # sanity check the error values\n",
    "    assert 3 < tr_error < 4 and 5 < val_error < 6\n",
    "    \n",
    "    mlp_tr_errors.append(tr_error)\n",
    "    mlp_val_errors.append(val_error)\n",
    "\n",
    "# sanity check the length of array mlp_tr_errors\n",
    "assert len(mlp_tr_errors) == len(mlp_val_errors) == len(num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:15:51.869761Z",
     "start_time": "2022-03-03T08:15:46.516472Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae45da73f5d125d48a28e806091c8bd1",
     "grade": true,
     "grade_id": "cell-a48ae1045910901d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests for A7.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:15:52.144366Z",
     "start_time": "2022-03-03T08:15:51.956426Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3628132249856a1e3299789ed8a30700",
     "grade": false,
     "grade_id": "cell-9a6da038de6b50d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(num_layers, mlp_tr_errors, label = 'Train')\n",
    "plt.plot(num_layers, mlp_val_errors,label = 'Valid')\n",
    "plt.xticks(num_layers)\n",
    "plt.legend(loc = 'upper left')\n",
    "\n",
    "plt.xlabel('Layers')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train vs validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:15:52.244826Z",
     "start_time": "2022-03-03T08:15:52.235079Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ecc68ee97e346ada446d2dc744f40ab",
     "grade": false,
     "grade_id": "cell-b341252a8e92dffa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create a table to compare the training and validation errors for MLPs with different number of hidden layers\n",
    "errors = {\"num_hidden_layers\":num_layers,\n",
    "          \"mlp_train_errors\":mlp_tr_errors,\n",
    "          \"mlp_val_errors\":mlp_val_errors,\n",
    "         }\n",
    "pd.DataFrame(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2b8bff95a3579940348778aec1ea4e2",
     "grade": false,
     "grade_id": "cell-f474967778ffc7ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "# Student Task A7.5\n",
    "\n",
    "Answer the following quiz questions by setting the corresponding variable to the index of the answer that you consider correct. \n",
    "    \n",
    "Question 1: Which of the models from A7.4 would you recommend based on the table above?\n",
    "- Answer 1: 1 hidden layer MLP\n",
    "- Answer 2: 2 hidden layers MLP\n",
    "- Answer 3: 4 hidden layers MLP\n",
    "- Answer 4: 6 hidden layers MLP\n",
    "- Answer 5: 8 hidden layers MLP\n",
    "- Answer 6: 10 hidden layers MLP \n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:16:06.584115Z",
     "start_time": "2022-03-03T08:16:06.573925Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0fe9580fd61267046dbde238f08aeaa7",
     "grade": false,
     "grade_id": "cell-f8ce50fe6bec05a2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## set Answer_Q1 to the index (starting from 1 !!!) of the correct answer (e.g., Answer_Q1=1 if you think Answer 1 is correct)\n",
    "Answer_Q1  = 2\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(f\"my answer is: Answer {Answer_Q1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:16:07.340032Z",
     "start_time": "2022-03-03T08:16:07.331673Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad6d93d6f66c9847c7ece07b9d494b8a",
     "grade": false,
     "grade_id": "cell-775fb9fd3780bd27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check datatype of Answer_Q1\n",
    "assert Answer_Q1 in (1, 2, 3, 4, 5, 6), \"Please answer with a number 1-6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:16:08.023613Z",
     "start_time": "2022-03-03T08:16:08.016747Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5398374f986bdc35d8f723fddf1a3a54",
     "grade": true,
     "grade_id": "cell-49b3a7a0bce155f0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests for A7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:16:08.836515Z",
     "start_time": "2022-03-03T08:16:08.816092Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c3f5d8c27f4469185c4ef8d6dfb9781",
     "grade": false,
     "grade_id": "cell-987c056f0add5ac1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "l_errors = {\"poly degree\":degrees,\"linear_train_errors\":linear_tr_errors, \"linear_val_errors\":linear_val_errors,}\n",
    "print(\"training errors and validation errors of PolynomialRegression\")\n",
    "pd.DataFrame(l_errors).style.applymap(lambda x: \"background-color: yellow\" if x==np.max(linear_val_errors) else \"background-color: white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:16:10.662373Z",
     "start_time": "2022-03-03T08:16:10.626885Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "635a52938a68ea6852908e5af5c3c2d8",
     "grade": false,
     "grade_id": "cell-d4579bbbb37c63bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "m_errors = {\"mlp_train_errors\":mlp_tr_errors, \"mlp_val_errors\":mlp_val_errors}\n",
    "print(\"training errors and validation errors of MLP\")\n",
    "pd.DataFrame(errors).style.applymap(lambda x: \"background-color: yellow\" if x==np.max(mlp_val_errors) else \"background-color: white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47708e699ab763914cc21ac1e4e9cf69",
     "grade": false,
     "grade_id": "cell-67ccb92c632604a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**PolynomialRegression vs MLP**\n",
    "\n",
    "The tables above compare the performance of PolynomialRegression and MLP on this specific ML problem. We can see that their performances are similar, but MLP is a bit better than PolynomialRegression. Considering sampling randomness, this suggests that deep learning methods are not always undisputed winners, particularly for simpler tasks where a simple model would train faster, predict quicker, and achieve comparable results.\n",
    "\n",
    "However, one significant advantage of MLP, even for simple problems, is that it is much less sensitive to model complexity than regression, so even without careful hyperparameter tuning the network always somehow 'does the job for us' with decent validation errors ~5, while regression explodes with an error of 18+ when we use a too complex model (max poly degree=4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T18:26:10.154646Z",
     "start_time": "2022-02-09T18:26:10.127219Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2121c2e2435f3762ac554f2367b19090",
     "grade": false,
     "grade_id": "cell-d0945c2202eeafb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "# Student Task A7.6\n",
    "    \n",
    "    \n",
    "**Train MLP classifiers and evaluate them on both training set and validation set.**\n",
    "    \n",
    "**Problem Formulation**: just like in Assingment3, we first categorize air temperature into 4 categories, for each datapoint (a day), the label is categorized air temperature of a given day at 00:00 and the features are air temperatures of previous 5 days at 00:00. \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "**Hypothesis Space - MLP Structure:**\n",
    "\n",
    "\n",
    "- one input layer consists of the individual features (5 features) and is the entry point to the MLP\n",
    "- several hidden layers with 10 neuron units and [ReLU activation function](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)), we will explore the number of hidden layers in this task, find out the ideal number of hidden layers for this given ML problem.\n",
    "\n",
    "- one final output layer with 4 neuron units and [softmax activation function](https://en.wikipedia.org/wiki/Softmax_function)\n",
    "\n",
    "For regularization strength and learning rate, default values are used.\n",
    "\n",
    "**Loss**: log-loss\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:23:09.803161Z",
     "start_time": "2022-03-03T08:23:09.784153Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62c1c88609403662479c34c3a2b8e21b",
     "grade": false,
     "grade_id": "cell-9a883950af87c395",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## dataset preparing\n",
    "minvalue = y.min() # minimum of the column 'air temperature'\n",
    "maxvalue = y.max() # maximum of the column 'air temperature'\n",
    "    \n",
    "labels = [0,1,2,3] # new labels to be assigned\n",
    "cut_bins = [minvalue,0,5,10,maxvalue] #cutting intervals/criteria\n",
    "\n",
    "# encode air temperatures (label) to categorical labels\n",
    "y_clf = pd.cut(y, bins=cut_bins,labels=labels,include_lowest=True).to_numpy()\n",
    "\n",
    "# features remain same, but assign different variable name to make the names more consistent\n",
    "X_clf = np.copy(X)\n",
    "\n",
    "# split data into training set and validation set\n",
    "X_clf_train, X_clf_val, y_clf_train, y_clf_val = train_test_split(X_clf, y_clf, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7d1abd43ef6c4fde6e8b07a27ebef00",
     "grade": false,
     "grade_id": "cell-f07d0e1332bd6a4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">    \n",
    "\n",
    "In the following solution cell, you will:\n",
    "- Initialise an MLPClassifier, please use the `hidden_layer_sizes` defined for you and set `max_iter` to 5000, `learning_rate_init` to 0.0001 and `random_state` to 0.\n",
    "- Train the classifier on the training set.\n",
    "- Evaluate the classifier on the training set and validation set.\n",
    "\n",
    "    \n",
    "**Sklearn class**: [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)  provides the methods you need to complete model training.\n",
    "\n",
    "**Model performance evaluation**: calculate the train and validation accuracy (average **0/1 loss**). The function [accuracy_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) has been imported for you in the beginning of this notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T07:29:13.744190Z",
     "start_time": "2022-03-02T07:29:13.737582Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "866933bdaf79cf9432acc53f4fd139dc",
     "grade": false,
     "grade_id": "cell-681e1f2914dc11e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:24:24.146779Z",
     "start_time": "2022-03-03T08:23:36.860475Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70794bd0c0513201b977c269ec32a72d",
     "grade": false,
     "grade_id": "cell-26ae8fe760a9e1c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Note: the execution time of this cell might be > 2 mins\n",
    "## define a list of values for the number of hidden layers\n",
    "num_layers_clf = [1,2,4,6,8,10]    # number of hidden layers,\n",
    "num_neurons = 10       # number of neurons of each layer, we fix this to 10 in this task\n",
    "\n",
    "\n",
    "# we will use this variables to store the resulting training accs for each number of hidden layers\n",
    "mlp_tr_accs = []          \n",
    "mlp_val_accs = []\n",
    "\n",
    "for i,num in enumerate(num_layers_clf):  \n",
    "    hidden_layer_sizes = tuple([num_neurons]*num) \n",
    "    \n",
    "    mlp_clf = MLPClassifier(hidden_layer_sizes = hidden_layer_sizes, max_iter = 5000, learning_rate_init = 0.0001, random_state = 0)           # initialise a MLPClassifier\n",
    "    mlp_clf.fit(X_clf_train, y_clf_train)    # train the calssifier\n",
    "   \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    y_pred_train = mlp_clf.predict(X_clf_train)    # predict using the trained model\n",
    "    tr_acc = accuracy_score(y_clf_train, y_pred_train)    # calculate the training acc\n",
    "    \n",
    "    y_pred_val = mlp_clf.predict(X_clf_val) # predict for the validation data \n",
    "    val_acc =  accuracy_score(y_clf_val, y_pred_val) # calculate the validation acc\n",
    "    \n",
    "    # sanity check num of layers\n",
    "    assert mlp_clf.n_layers_ == num_layers_clf[i]+2 # num of total layers \n",
    "    # sanity check the acc values\n",
    "    assert 0.8 < tr_acc < 0.9 and 0.7 < val_acc < 0.85\n",
    "    \n",
    "    mlp_tr_accs.append(tr_acc)\n",
    "    mlp_val_accs.append(val_acc)\n",
    "\n",
    "# sanity check the length of array tr_accs\n",
    "assert len(mlp_tr_accs) == len(mlp_val_accs) == len(num_layers_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T07:30:06.222093Z",
     "start_time": "2022-03-02T07:30:06.072489Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ad743ea5adc2114351125d2b5630bee",
     "grade": false,
     "grade_id": "cell-9a6da138de6b50d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(num_layers_clf, mlp_tr_accs, label = 'Train')\n",
    "plt.plot(num_layers_clf, mlp_val_accs,label = 'Valid')\n",
    "plt.xticks(num_layers_clf)\n",
    "plt.legend(loc = 'upper left')\n",
    "\n",
    "plt.xlabel('Layers')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Train vs validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T07:30:06.241750Z",
     "start_time": "2022-03-02T07:30:06.224609Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86d46f2e5c4b2e30fa6f322143c77556",
     "grade": false,
     "grade_id": "cell-45b5df8a9fff2f6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "accus = {\"num_hidden_layers\":num_layers_clf,\n",
    "          \"MLP_train_accs\":mlp_tr_accs,\n",
    "          \"MLP_val_accs\":mlp_val_accs,\n",
    "         }\n",
    "pd.DataFrame(accus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c91a5bf84c6b73140d24ea4a8b22405",
     "grade": false,
     "grade_id": "cell-8d704d02520b497a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "# Student Task A7.7\n",
    "\n",
    "Answer the following quiz questions by setting the corresponding variable to the index of the answer that you consider correct. \n",
    "    \n",
    "Question 1: Which of the models from A7.6 would you recommend based on the table above?\n",
    "- Answer 1: 1 hidden layer MLP\n",
    "- Answer 2: 2 hidden layers MLP\n",
    "- Answer 3: 4 hidden layers MLP\n",
    "- Answer 4: 6 hidden layers MLP\n",
    "- Answer 5: 8 hidden layers MLP\n",
    "- Answer 6: 10 hidden layers MLP \n",
    "- Answer 7: 12 hidden layers MLP\n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T07:30:06.256109Z",
     "start_time": "2022-03-02T07:30:06.246680Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f3a090152b7fb578284aef1bbf1ea41",
     "grade": false,
     "grade_id": "cell-e2bdd89150d1112d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## set Answer_Q1 to the index (starting from 1 !!!) of the correct answer (e.g., Answer_Q1=1 if you think Answer 1 is correct)\n",
    "Answer_Q1  = 5  \n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(f\"my answer is: Answer {Answer_Q1}\")\n",
    "assert Answer_Q1 in range(1,8), \"Please use an int in the range [1,7] for your answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T07:30:06.266133Z",
     "start_time": "2022-03-02T07:30:06.259909Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8091428e868207ae168f53131fce674",
     "grade": true,
     "grade_id": "cell-d0cf2c2a51430269",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests for A7.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a22c122156ffdf09dab0938af3f58fb",
     "grade": false,
     "grade_id": "cell-7f2ee7806f4ff138",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-info\">\n",
    "\n",
    "# Demo: Learning rate\n",
    "The main learning algorithm for deep learning is gradient descent. From calculus courses, you should be familiar with what a gradient (or a derivative for a single variable function) represents. By using it, we can learn how our function is behaving in a given datapoint (is it rising or falling?), and based on that, we know 'which direction to go' in order to minimize it. Neural networks learn by computing the gradient of the loss function, which gives them the information on how to change their weights to move towards the local minimum.\n",
    "\n",
    "Typically we would take an average direction based on a batch of datapoints, usually 16/32/64 of them at a time. However, the gradient just gives us the direction, we do not know how far in that direction we should go. We control that using a number called the **learning rate**, which lets us scale the steps we take. \n",
    "```\n",
    "weight_update = update_from_the_gradient * learning_rate\n",
    "```\n",
    "\n",
    "If we are too careful and set a very small learning rate, taking baby steps towards the minimum, our training would take too long. On the other hand, if the learning rate is too big, we might 'overshoot', and keep missing the optimal point. This means that learning rate is usually the most important training parameter and should be chosen carefully, and even adjusted during the training - luckily most libraries provide us with good default values and training algorithms.\n",
    "\n",
    "Gradient descent is a complex topic, and the above explanation is very simplified. We highly recommend [this video](https://www.youtube.com/watch?v=IHZwWFHWa-w) by 3blue1brown, showing the process in greater detail, with easy to understand animations. \n",
    "    \n",
    "Take a look at the code below, showing what happens to the training process when we change the learning rate:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:33:20.788719Z",
     "start_time": "2022-03-03T08:33:01.451112Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5656f34fd0b4b1242ce372bc439a9dde",
     "grade": false,
     "grade_id": "cell-668b13f6abe8b2e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lrs = [1e-07,0.0001,0.002]  # 3 different learning rate\n",
    "fig, axes = plt.subplots(1,3, sharey=True, figsize=(15,4))\n",
    "for i, lr in enumerate(lrs):\n",
    "    mlp_regr = MLPRegressor((10,15,15,10),max_iter=3000,batch_size=64,\\\n",
    "                            solver='sgd',learning_rate_init=lr,random_state=42) \n",
    "    mlp_regr.fit(X_train, y_train)    # Train MLP on the training set\n",
    "    axes[i].plot(mlp_regr.loss_curve_[:1000]) \n",
    "    axes[i].set_title(f'lr={lr}\\n minimum loss={mlp_regr.loss_}')\n",
    "    axes[i].set_ylabel('Loss')\n",
    "    axes[i].set_yticks(np.arange(0,80,5))\n",
    "    axes[i].set_xlabel('optimization iterations')\n",
    "plt.show()\n",
    "\n",
    "#NOTE: The warning you see is for the first learning rate 1e-07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef71cba78e806ad0dd6274ecb3fbac83",
     "grade": false,
     "grade_id": "cell-b22fba375c2d2948",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "# Student task A7.8\n",
    "Answer the following quiz questions by setting the corresponding variable to the index of the answer that you consider correct:\n",
    "    \n",
    "Question1: 'Larger learning rate is always better, since it lets our model converge faster, reducing the length of the trainig.' - is this sentence true or false?\n",
    "- Answer 1: True\n",
    "- Answer 2: False\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8847cbd07a95a66e06ff65970f3167f",
     "grade": false,
     "grade_id": "cell-c741f3c908e8bd33",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## set Answer_Q1 to the index (starting from 1 !!!) of the correct answer (e.g., Answer_Q1=1 if you think Answer 1 is correct)\n",
    "Answer_Q1 = 2   \n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(f\"my answer is: Answer {Answer_Q1}\")\n",
    "assert Answer_Q1 in (1,2), \"Please use 1 or 2 for your answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b315387ee4e13306c4a473ac99b8a7bf",
     "grade": true,
     "grade_id": "cell-bf07472d7d7c9124",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests for A7.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3acd59badd423c67d435950031e17f92",
     "grade": false,
     "grade_id": "cell-ee20b38943a09f44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-info\">\n",
    "\n",
    "# Demo: Grid search\n",
    "By now, you have experienced model selections based on different parameters, such as max poly degree for Polynomial Regression, alpha for Ridge Regression, number of hidden layers for MLP, etc.\n",
    "These parameters are called hyperparameters, because they are not directly learnt within regressors/classifiers, but rather a property of the training process selected by humans. In sklearn they are passed as arguments to the constructor of the regressor/classifier instances or feature transforming classes. \n",
    "\n",
    "In previous assignments and tasks, We used for loops to iterate a list of candidate hyperparameters to train corresponding models and compare the train/validation errors to do final model selection/adjusting. But most models, especially complicated models such as ANNs, have multiple hyper-parameters. Using (deeply) nested for-loops to search for a best combination from a large hyper-parameter space will make the code quite tedious, so sklearn provides a grid search method [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)\n",
    "to exhaustively search candidates from a grid of parameter values specified with the `param_grid` parameter. For instance, the following param_grid will be used in this demo of hyperparameters for tuning/adjusting the MLPClassifier:\n",
    "    \n",
    "<code> param_grid = {\n",
    "    'hidden_layer_sizes': [(15,15),(10)],\n",
    "    'learning_rate_init':[0.001,0.01]\n",
    "}\n",
    "</code>\n",
    "\n",
    "We first define the model (mlp_grids). GridSearchCV method is used to `fit()` the model for different combinations of the hyper-parameters specified in `param_grid` and give the best combination based on the validation accuracies. `cv` is the parameter to specify how many folds will be used for cross validation. For more details, please read the documentation.   \n",
    "\n",
    "Note: Do not worry about ConvergenceWarnings - since we try various hyperparameters, it is normal that not all of the models converge properly.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:55:24.476622Z",
     "start_time": "2022-03-03T08:52:37.325860Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6a0ad56740818b052faa63b31517e65",
     "grade": false,
     "grade_id": "cell-12958ed011d24502",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Note: the execution time of this cell might be > 2 mins\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mlp_grids = MLPClassifier(max_iter=3000,random_state=1)\n",
    "\n",
    "## to limit the executive time, a small hyper-parameter space is used, you can feel free to expand the space,\n",
    "## such as adding more candidate network sizes, learning rates or the other hyper-parameters.\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(15,15),(10)],     # different depth and width of the network\n",
    "    'learning_rate_init':[0.001,0.01]          # different learning rate\n",
    "}\n",
    "\n",
    "classifier = GridSearchCV(estimator=mlp_grids,param_grid=param_grid,cv=5,return_train_score=True)\n",
    "classifier = classifier.fit(X_clf,y_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:55:28.584978Z",
     "start_time": "2022-03-03T08:55:28.579020Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8aa76fdf7efadca2b76a85471cc985aa",
     "grade": false,
     "grade_id": "cell-7eaeea9b58b95437",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# to see the best hyperparameter combination\n",
    "print('Best hyper-parameters found:\\n\\n', classifier.best_params_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T06:28:54.922650Z",
     "start_time": "2022-03-01T06:28:54.869332Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89053246dbab78b7c81000776bb11a60",
     "grade": false,
     "grade_id": "cell-dc60df3d58db6a1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "# Student Task A7.9\n",
    "Please carefully read the documentation of [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV), figure out how to obtain the attribute: best score (it is the best validation accuracy) for the classifiers trained in the demo and assign it to the variable `best_accuracy`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:55:30.175332Z",
     "start_time": "2022-03-03T08:55:30.165701Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4432d4292d3426ec705b1dbe2abaa330",
     "grade": false,
     "grade_id": "cell-00319d39c3087915",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "best_accuracy = classifier.best_score_\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print('Best validation accuracy:\\n\\n', best_accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:51:23.109252Z",
     "start_time": "2022-03-03T08:51:23.105054Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56feb1e8ea4349d2b8ac2d4cb42f7cb1",
     "grade": true,
     "grade_id": "cell-fb6880f910793875",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this is the test cell for A7.9\n",
    "### BEGIN HIDDEN TESTs\n",
    "assert np.isclose(best_accuracy,classifier.best_score_)\n",
    "### END HIDDEN TESTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "049e45db35e6866f31e54525ceafb1d1",
     "grade": false,
     "grade_id": "cell-7d68ae192885ac0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\" alert alert-warning\">\n",
    "\n",
    "# Student Task A7.10\n",
    "Answer the following quiz questions by setting the corresponding variable to the index of the answer that you consider correct. \n",
    "\n",
    "Question 1: \"If the activation functions are all linear functions, Neural Network only acts as a linear hypothesis mapper.\" Is this statement correct?\n",
    "- Answer 1: Yes, it is correct.\n",
    "- Answer 2: No, it is not correct.\n",
    "    \n",
    "Question 2: \"Neural Networks can approximate any continuous function.\" Is this statement correct?\n",
    "- Answer 1: Yes, it is correct.\n",
    "- Answer 2: No, it is not correct.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:50:55.398864Z",
     "start_time": "2022-03-03T08:50:55.392529Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8269d5dfbd75596a439f81837769c526",
     "grade": false,
     "grade_id": "cell-73a71928482be90a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## set Answer_Q1 and Answer_Q2 to the index (starting from 1 !!!) of the correct answer (e.g., Answer_Q2=1 if you think Answer 1 is correct)\n",
    "Answer_Q1 = 1\n",
    "Answer_Q2 = 1  \n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"My answer for Question1 is:\", Answer_Q1)\n",
    "print(\"My answer for Question2 is:\", Answer_Q2)\n",
    "\n",
    "assert Answer_Q1 in [1,2] \n",
    "assert Answer_Q2 in [1,2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T08:50:56.333209Z",
     "start_time": "2022-03-03T08:50:56.328661Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b63d224ac137f270ffe3054be97e4eae",
     "grade": true,
     "grade_id": "cell-8c36c0acfc6c7ae0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests for A7.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T07:32:59.384832Z",
     "start_time": "2022-03-02T07:32:59.372400Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74b812db59843fea482a0266bdb161cb",
     "grade": true,
     "grade_id": "cell-612db0bb5cf7f1d6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell is for tests for A7.10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "210.796875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
